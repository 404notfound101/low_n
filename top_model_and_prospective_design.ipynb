{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2193860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import tape\n",
    "import sklearn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import random\n",
    "from sklearn.linear_model import LassoLars, LassoLarsCV, Ridge, RidgeCV, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from torch import nn\n",
    "from tape import TAPETokenizer\n",
    "from tape import UniRepForLM\n",
    "import copy\n",
    "\n",
    "sys.path.append('../common')\n",
    "import data_io_utils\n",
    "import paths\n",
    "import utils\n",
    "import constants\n",
    "\n",
    "import A003_common\n",
    "import acquisition_policies\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3660c08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cu111'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfaf182",
   "metadata": {},
   "source": [
    "# load language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ba7799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniRepForLM(\n",
       "  (unirep): UniRepModel(\n",
       "    (embed_matrix): Embedding(26, 10)\n",
       "    (encoder): mLSTM(\n",
       "      (mlstm_cell): mLSTMCell(\n",
       "        (wmx): Linear(in_features=10, out_features=1900, bias=False)\n",
       "        (wmh): Linear(in_features=1900, out_features=1900, bias=False)\n",
       "        (wx): Linear(in_features=10, out_features=7600, bias=False)\n",
       "        (wh): Linear(in_features=1900, out_features=7600, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feedforward): Linear(in_features=1900, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UniRepForLM.from_pretrained(\"babbler-1900\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a770625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UniRepForLM.from_pretrained(\"babbler-1900\")\n",
    "model.feedforward = nn.Linear(1900,26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"fp16_64_trial_fine_turning.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#epoch = checkpoint['epoch']\n",
    "#loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10401e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniRepForLM(\n",
       "  (unirep): UniRepModel(\n",
       "    (embed_matrix): Embedding(26, 10)\n",
       "    (encoder): mLSTM(\n",
       "      (mlstm_cell): mLSTMCell(\n",
       "        (wmx): Linear(in_features=10, out_features=1900, bias=False)\n",
       "        (wmh): Linear(in_features=1900, out_features=1900, bias=False)\n",
       "        (wx): Linear(in_features=10, out_features=7600, bias=False)\n",
       "        (wh): Linear(in_features=1900, out_features=7600, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feedforward): Linear(in_features=1900, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d93b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "model.feedforward = Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdb64e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniRepForLM(\n",
       "  (unirep): UniRepModel(\n",
       "    (embed_matrix): Embedding(26, 10)\n",
       "    (encoder): mLSTM(\n",
       "      (mlstm_cell): mLSTMCell(\n",
       "        (wmx): Linear(in_features=10, out_features=1900, bias=False)\n",
       "        (wmh): Linear(in_features=1900, out_features=1900, bias=False)\n",
       "        (wx): Linear(in_features=10, out_features=7600, bias=False)\n",
       "        (wh): Linear(in_features=1900, out_features=7600, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feedforward): Identity()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db948dde",
   "metadata": {},
   "source": [
    "# training data for top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7baf598",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_qfunc = pickle.load( open( \"training.p\", \"rb\" ) )\n",
    "training_embedding = emb_qfunc[\"embedding\"]\n",
    "training_qfunc = emb_qfunc[\"qfunc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76b94a",
   "metadata": {},
   "source": [
    "# Validation data for top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6120536",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_qfunc = pickle.load( open( \"validation.p\", \"rb\" ) )\n",
    "validation_embedding = emb_qfunc[\"embedding\"]\n",
    "validation_qfunc = emb_qfunc[\"qfunc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6abc5b",
   "metadata": {},
   "source": [
    "# embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7885f28",
   "metadata": {},
   "source": [
    "# top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "058b467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_MODEL_DO_SPARSE_REFIT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62f0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoLars_model = A003_common.cv_train_lasso_lars_with_sparse_refit(\n",
    "                training_embedding, training_qfunc, do_sparse_refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dbcf6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_model = A003_common.cv_train_ridge_with_sparse_refit(\n",
    "                training_embedding, training_qfunc, do_sparse_refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c462dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "BayesianRidge_model = A003_common.train_blr(training_embedding, training_qfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "495666ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnsembledRidge = A003_common.train_ensembled_ridge(\n",
    "                training_embedding, \n",
    "                training_qfunc, \n",
    "                do_sparse_refit=TOP_MODEL_DO_SPARSE_REFIT, \n",
    "                n_members=100, \n",
    "                subspace_proportion=0.5, \n",
    "                pval_cutoff=0.01, \n",
    "                normalize=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3525fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = A003_common.cv_train_knn(\n",
    "                training_embedding, training_qfunc, do_sparse_refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fece9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TAPETokenizer(vocab='unirep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e096d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results = EnsembledRidge.predict(validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "_, _, r_value, _ , _ = scipy.stats.linregress(validation_embedding, validation_qfunc)\n",
    "pred_vs_actual_df = pd.DataFrame(np.ones(len(validation_embedding)))\n",
    "pred_vs_actual_df[\"actual\"] = validation_qfunc\n",
    "pred_vs_actual_df[\"predicted\"] = validation_embedding\n",
    "pred_vs_actual_df.drop(columns=0, inplace=True)\n",
    "pred_vs_actual_df.head()\n",
    "#--------------------------------------------------#\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "y_interval=max(np.concatenate((validation_qfunc, validation_qfunc),axis=0))-min(np.concatenate((validation_qfunc, validation_qfunc),axis=0))\n",
    "x_y_range=(min(np.concatenate((validation_qfunc, validation_qfunc),axis=0))-0.1*y_interval, max(np.concatenate((validation_qfunc, validation_qfunc),axis=0))+0.1*y_interval)\n",
    "g = sns.jointplot(x=\"actual\", y=\"predicted\", data=pred_vs_actual_df,\n",
    "                kind=\"reg\", truncate=False,\n",
    "                xlim=x_y_range, ylim=x_y_range,\n",
    "                color=\"blue\",height=7)\n",
    "\n",
    "g.fig.suptitle(\"Predictions vs. Actual Values, R = \" + str(round(r_value,3)) , fontsize=18, fontweight='bold')\n",
    "g.fig.tight_layout()\n",
    "g.fig.subplots_adjust(top=0.95)\n",
    "g.ax_joint.text(0.4,0.6,\"\", fontsize=12)\n",
    "g.ax_marg_x.set_axis_off()\n",
    "g.ax_marg_y.set_axis_off()\n",
    "g.ax_joint.set_xlabel('Actual Values',fontsize=18 ,fontweight='bold')\n",
    "g.ax_joint.set_ylabel('Predictions',fontsize=18 ,fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef67291",
   "metadata": {},
   "source": [
    "# MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64e0a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_ANNEAL_K = 1\n",
    "SIM_ANNEAL_INIT_SEQ_MUT_RADIUS = 3\n",
    "n_chains = 350\n",
    "T_max = 0.01*np.ones(3500)\n",
    "GFP_LIB_REGION = [29, 110]\n",
    "seed = 9\n",
    "temp_decay_rate = 1.0\n",
    "sa_n_iter = 30000\n",
    "nmut_threshold = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3edc1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e4f928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptance_prob(f_proposal, f_current, k, T):\n",
    "    ap = np.exp((f_proposal - f_current)/(k*T))\n",
    "    ap[ap > 1] = 1\n",
    "    return ap\n",
    "\n",
    "def make_n_random_edits(seq, nedits, alphabet=constants.AA_ALPHABET_STANDARD_ORDER,\n",
    "        min_pos=None, max_pos=None): ## Test\n",
    "    \"\"\"\n",
    "    min_pos is inclusive. max_pos is exclusive\n",
    "    \"\"\"\n",
    "    \n",
    "    lseq = list(seq)\n",
    "    lalphabet = list(alphabet)\n",
    "    \n",
    "    if min_pos is None:\n",
    "        min_pos = 0\n",
    "    \n",
    "    if max_pos is None:\n",
    "        max_pos = len(seq)\n",
    "    \n",
    "    # Create non-redundant list of positions to mutate.\n",
    "    l = list(range(min_pos, max_pos))\n",
    "    nedits = min(len(l), nedits)\n",
    "    random.shuffle(l)\n",
    "    pos_to_mutate = l[:nedits]    \n",
    "    \n",
    "    for i in range(nedits):\n",
    "        pos = pos_to_mutate[i]     \n",
    "        aa_to_choose_from = list(set(lalphabet) - set([seq[pos]]))\n",
    "                        \n",
    "        lseq[pos] = aa_to_choose_from[np.random.randint(len(aa_to_choose_from))]\n",
    "        \n",
    "    return \"\".join(lseq)\n",
    "\n",
    "def propose_seqs(seqs, mu_muts_per_seq, min_pos=None, max_pos=None):\n",
    "    \n",
    "    mseqs = []\n",
    "    for i,s in enumerate(seqs):\n",
    "        n_edits = np.random.poisson(mu_muts_per_seq[i]-1) + 1\n",
    "        mseqs.append(make_n_random_edits(s, n_edits, min_pos=min_pos, max_pos=max_pos)) \n",
    "        \n",
    "    return mseqs\n",
    "\n",
    "\n",
    "def anneal(\n",
    "        init_seqs, \n",
    "        k, \n",
    "        T_max, \n",
    "        mu_muts_per_seq,\n",
    "        get_fitness_fn,\n",
    "        n_iter=1000, \n",
    "        decay_rate=0.99,\n",
    "        min_mut_pos=None,\n",
    "        max_mut_pos=None):\n",
    "    \n",
    "    print('Initializing')\n",
    "    state_seqs = copy.deepcopy(init_seqs)\n",
    "    state_fitness, state_fitness_std, state_fitness_mem_pred = get_fitness_fn(state_seqs)\n",
    "    \n",
    "    seq_history = [copy.deepcopy(state_seqs)]\n",
    "    fitness_history = [copy.deepcopy(state_fitness)]\n",
    "    fitness_std_history = [copy.deepcopy(state_fitness_std)]\n",
    "    fitness_mem_pred_history = [copy.deepcopy(state_fitness_mem_pred)]\n",
    "    for i in range(n_iter):\n",
    "        print('Iteration:', i)\n",
    "        \n",
    "        print('\\tProposing sequences.')\n",
    "        proposal_seqs = propose_seqs(state_seqs, mu_muts_per_seq, \n",
    "                min_pos=min_mut_pos, max_pos=max_mut_pos)\n",
    "        \n",
    "        print('\\tCalculating predicted fitness.')\n",
    "        proposal_fitness, proposal_fitness_std, proposal_fitness_mem_pred = get_fitness_fn(proposal_seqs)\n",
    "        \n",
    "        \n",
    "        print('\\tMaking acceptance/rejection decisions.')\n",
    "        aprob = acceptance_prob(proposal_fitness, state_fitness, k, T_max*(decay_rate**i))\n",
    "        \n",
    "        # Make sequence acceptance/rejection decisions\n",
    "        for j, ap in enumerate(aprob):\n",
    "            if np.random.rand() < ap:\n",
    "                # accept\n",
    "                state_seqs[j] = copy.deepcopy(proposal_seqs[j])\n",
    "                state_fitness[j] = copy.deepcopy(proposal_fitness[j])\n",
    "                state_fitness_std[j] = copy.deepcopy(proposal_fitness_std[j])\n",
    "                state_fitness_mem_pred[j] = copy.deepcopy(proposal_fitness_mem_pred[j])\n",
    "            # else do nothing (reject)\n",
    "            \n",
    "        seq_history.append(copy.deepcopy(state_seqs))\n",
    "        fitness_history.append(copy.deepcopy(state_fitness))\n",
    "        fitness_std_history.append(copy.deepcopy(state_fitness_std))\n",
    "        fitness_mem_pred_history.append(copy.deepcopy(state_fitness_mem_pred))\n",
    "        \n",
    "    return {\n",
    "        'seq_history': seq_history,\n",
    "        'fitness_history': fitness_history,\n",
    "        'fitness_std_history': fitness_std_history,\n",
    "        'fitness_mem_pred_history': fitness_mem_pred_history,\n",
    "        'init_seqs': init_seqs,\n",
    "        'T_max': T_max,\n",
    "        'mu_muts_per_seq': mu_muts_per_seq,\n",
    "        'k': k,\n",
    "        'n_iter': n_iter,\n",
    "        'decay_rate': decay_rate,\n",
    "        'min_mut_pos': min_mut_pos,\n",
    "        'max_mut_pos': max_mut_pos,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd6972a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_muts_per_seq: [1.79368457 1.77927441 1.21903641 ... 1.88690493 1.45501428 2.23954184]\n"
     ]
    }
   ],
   "source": [
    "init_seqs = propose_seqs(\n",
    "        [constants.AVGFP_AA_SEQ]*n_chains, \n",
    "        [SIM_ANNEAL_INIT_SEQ_MUT_RADIUS]*n_chains, \n",
    "        min_pos=GFP_LIB_REGION[0], \n",
    "        max_pos=GFP_LIB_REGION[1])\n",
    "mu_muts_per_seq = 1.5*np.random.rand(n_chains) + 1\n",
    "print('mu_muts_per_seq:', mu_muts_per_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "909ce77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitness(seqs):\n",
    "    tokens = []\n",
    "    for seq in seqs:\n",
    "        token_ids = torch.tensor([tokenizer.encode(seq)])\n",
    "        tokens.append(token_ids)\n",
    "    inputs = torch.stack(tokens,dim = 0).view(-1,240)\n",
    "    inputs = inputs.cuda()\n",
    "    output = model(inputs)\n",
    "    embedding = torch.mean(output[0][:,1:-1,:],1)\n",
    "    reps = embedding.cpu().detach().numpy()\n",
    "\n",
    "    yhat, yhat_std, yhat_mem = EnsembledRidge.predict(reps, \n",
    "            return_std=True, return_member_predictions=True)\n",
    "                \n",
    "    nmut = utils.levenshtein_distance_matrix(\n",
    "            [constants.AVGFP_AA_SEQ], list(seqs)).reshape(-1)\n",
    "        \n",
    "    mask = nmut > nmut_threshold\n",
    "    yhat[mask] = -np.inf \n",
    "    yhat_std[mask] = 0 \n",
    "    yhat_mem[mask,:] = -np.inf \n",
    "        \n",
    "    return yhat, yhat_std, yhat_mem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_results = anneal(init_seqs,k=SIM_ANNEAL_K,T_max=T_max,mu_muts_per_seq=mu_muts_per_seq,get_fitness_fn=get_fitness,n_iter=sa_n_iter,decay_rate=temp_decay_rate,min_mut_pos=GFP_LIB_REGION[0],max_mut_pos=GFP_LIB_REGION[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ba6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(sa_results,'result.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
